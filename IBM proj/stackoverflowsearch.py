# -*- coding: utf-8 -*-
"""StackOverflowSearch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18o4b6Z0XR9JpPIWoN4612pprp3y2jdL5

## Downloading Packages
This step is required to be carried out in the beginning of new session.
"""

import nltk
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('vader_lexicon')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

!pip install stackapi
!pip install twython

"""###Importing Modules"""

import re
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import wordnet as wn
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from stackapi import StackAPI

"""##Defining Constants"""

k = 10
SITE = StackAPI('stackoverflow')

"""#Problem 1
##To identify most relevant questions to a query (text similarity)

###Get query from the user
This is the same query that user would enter in the search field of StackOverflow.
"""

query = input("Enter the query: ")

"""###Extracting tags from the query
Extract keywords from the query into a list and then shorten the list.

NOTE: This can be further improved by extracting tags using StackOverflow tags dataset.
"""

#Remove punctuations
text = re.sub('[^a-zA-Z]', ' ', query)
#Convert to lowercase
text = text.lower()
#Remove tags
text = re.sub("&lt;/?.*?&gt;"," &lt;&gt; ",text)
#Remove special characters and digits
text = re.sub("(\\d|\\W)+"," ",text)
#Convert to list from string
text = text.split()



#Reduce the list
stop_words = set(stopwords.words("english"))
cv = CountVectorizer(max_df=0.8, stop_words=stop_words, max_features=10000, ngram_range=(1,3))
X = cv.fit_transform(text)
shortened_list = list(cv.vocabulary_.keys())[:10]
print("Query: " + str(query))
print("Tags: " + str(shortened_list))

"""###Getting questions from the tags using StackAPI"""

tags_string = " ".join(shortened_list)

#Fetching list of questions into questions_json
questions_json = SITE.fetch('search/excerpts', q=tags_string, sort='relevance', filter = '!)Q29nl5DNb5bipTWVFKCiZie')

#Printing first k questions
for question in questions_json['items']:
  print(question['title'])

"""###Sorting questions based on ***text similarity*** scores
Calculate text similarity between user query and question title. 
Sort the question in order of their (cosine) scores and display them to the user.
"""

vect = TfidfVectorizer(min_df=1)

#Creating a dictionary of score and list of questions corresponding to the score
#Here, each question is represented as a dictionary of question_id, title, and body
score_question_dict = {}
for question in questions_json['items']:
  #Calculating text similairty between query and question title
  tfidf = vect.fit_transform([query, question['title']])
  #Considering cosine text similarity score
  question_score = ((tfidf * tfidf.T).A)[0,1]
  #Feeding in the dictionary
  if question_score not in score_question_dict.keys():
      score_question_dict[question_score] = [{'question_id':question['question_id'], 'title':question['title'], 'body':question['body']}]
  else: 
      score_question_dict[question_score] += [{'question_id':question['question_id'], 'title':question['title'], 'body':question['body']}]
        
#Printing question as they appear on the site with title and body
print(str(len(score_question_dict))+" Results")
for question_score in sorted(score_question_dict.keys(), reverse=True):
  for question in score_question_dict[question_score]:
    print(str(question['question_id']) + ": " + question['title'])
    print(question['body'])
    print("------------------------------------------------------")

"""###Get question_id from the user
Ask user to select a question from the list of questions using question_id. 

This is similar to user selecting the question (by clicking on the link) from the search results on StackOverflow website.
"""

question_id = int(input('Select a question: '))

"""#Problem 2
##To identify top k solutions of the selected question (Sentiment Analysis of review content)

###Getting answers to the selected question using StackAPI
"""

#Fetching answers to the selected question_id 
answers_json = SITE.fetch('questions/{ids}/answers', ids = [question_id], filter = '!*cCFgkLFk24i(9rKI)wpCc747lAHZul(ht_tD')

"""###Sorting questions based on sentiment analysis on their comments
Analyse all the comments to an answer for sentiment. Assign each answer a score based on this analysis. Sort the answers and display them to the user.
"""

sid = SentimentIntensityAnalyzer()

#Create a dictionary of score and list of answers corresponding to the score
#Here, each answer is represented as a dictionary of answer_id, question_id, question_title, answer_body
score_answer_dict = {}
#Perform sentiment analysis on all comments of each answer 
for answer_item in answers_json['items']:
  all_comments = []
  if 'comments' in answer_item.keys():
    #Collect all the comments in a list
    for comment in answer_item['comments'] :
      all_comments.append(comment['body_markdown'])
    ss = sid.polarity_scores(" ".join(all_comments))
    #Give more weightage to the positive score than neutral score
    sscore = ss["pos"]*2 + ss["neu"]
    if sscore not in score_answer_dict.keys():
      score_answer_dict[sscore] = [{'answer_id':answer_item['answer_id'], 'question_id':answer_item['question_id'], 
                                   'question_title':answer_item['title'], 'answer_body':answer_item['body_markdown']}]
    else: 
      score_answer_dict[sscore] += [{'answer_id':answer_item['answer_id'], 'question_id':answer_item['question_id'], 
                                   'question_title':answer_item['title'], 'answer_body':answer_item['body_markdown']}]
      
#Display the answers to the user sorted by sentiment analysis scores
print('Question (' + str(answers_json['items'][0]['question_id']) + "): " + str(answers_json['items'][0]['title']), end='\n\n')
for answer_score in sorted(score_answer_dict.keys(), reverse=True):
  for answer in score_answer_dict[answer_score]:
    print('Answer ID: ' + str(answer['answer_id']))
    print(answer['answer_body'])
    print("------------------------------------------------------")